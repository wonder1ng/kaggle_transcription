{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[이유한님] 캐글 코리아 캐글 스터디 커널 커리큘럼](https://kaggle-kr.tistory.com/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1st level. Costa Rican Household Poverty Level Prediction](https://www.kaggle.com/c/costa-rican-household-poverty-prediction)  \n",
    "'#'은 wonder1ng 각주  \n",
    "표기가 없거나 '##~'은 원본 각주(혹은 코드)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [A Complete Introduction and Walkthrough](https://www.kaggle.com/code/willkoehrsen/a-complete-introduction-and-walkthrough/notebook)"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costa Rican Household Poverty Level Prediction\n",
    "Welcome to another Kaggle challenge! The objective of the Costa Rican Household Poverty Level Prediction contest is to develop a machine learning model that can predict the poverty level of households using both individual and household characteristics. This \"data science for good\" project offers the opportunity to put our skills towards a task more beneficial to society than getting people to click on ads!  \n",
    "  \n",
    "In this notebook, we will walk through a complete machine learning solution: first, get introduced to the problem, then perform a thorough Exploratory Data Analysis of the dataset, work on feature engineering, try out multiple machine learning models, select a model, work to optimize the model, and finally, inspect the outputs of the model and draw conclusions. __While this notebook may not get us to the top of the leaderboard, it is meant to be used as a teaching tool to give you a solid foundation to build on for future machine learning projects. Kaggle projects can teach us a lot about machine learning, but several of the strategies used to get to the very top of the leaderboard are not best practices, so here we'll stick to building a very good - although not quite first place - machine learning solution. While Kaggle projects are competitions, I think they are best described as \"a machine learning education\" disguised as a contest!\"  \n",
    "  \n",
    "If you are looking to follow-up on this work, I have additional work including [a kernel on using Automated Feature Engineering](https://www.kaggle.com/code/willkoehrsen/featuretools-for-good/notebook) with [Featuretools](https://featuretools.alteryx.com/en/stable/#minute-quick-start) for this problem (with slightly higher leaderboard score). (If you enjoy my writing style and explanations, I write for [Towards Data Science](https://williamkoehrsen.medium.com/))  \n",
    "  \n",
    "### Problem and Data Explanation\n",
    "The data for this competition is provided in two files: train.csv and test.csv. The training set has 9557 rows and 143 columns while the testing set has 23856 rows and 142 columns. Each row represents __one individual__ and each column is a __feature, either unique to the individual, or for the household of the individual.__ The training set has one additional column, Target, which represents the poverty level on a 1-4 scale and is the label for the competition. A value of 1 is the most extreme poverty.  \n",
    "  \n",
    "This is a __supervised multi-class classification machine learning problem:__  \n",
    "  \n",
    "- __Supervised:__ provided with the labels for the training data  \n",
    "- __Multi-class classification:__ Labels are discrete values with 4 classes  \n",
    "  \n",
    "### Objective\n",
    "The objective is to predict poverty on a __household level__. We are given data on the individual level with each individual having unique features but also information about their household. In order to create a dataset for the task, we'll have to perform some aggregations of the individual data for each household. Moreover, we have to make a prediction for every individual in the test set, but \"ONLY the heads of household are used in scoring\" which means we want to predict poverty on a household basis.\n",
    "\n",
    "__Important note: while all members of a household should have the same label in the training data, there are errors where individuals in the same household have different labels. In these cases, we are told to use the label for the head of each household, which can be identified by the rows where `parentesco1 == 1.0`.__ We will cover how to correct this in the notebook (for more info take a look at the [competition main discussion](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403)).\n",
    "\n",
    "The `Target` values represent poverty levels as follows:\n",
    "\n",
    "`1 = extreme poverty`  \n",
    "`2 = moderate poverty`  \n",
    "`3 = vulnerable households`  \n",
    "`4 = non vulnerable households`\n",
    "  \n",
    "The explanations for all 143 columns can be found in the [competition documentation](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/data), but a few to note are below:\n",
    "\n",
    "- __Id:__ a unique identifier for each individual, this should not be a feature that we use!\n",
    "- __idhogar:__ a unique identifier for each household. This variable is not a feature, but will be used to group individuals by household as all individuals in a household will have the same identifier.\n",
    "- __parentesco1:__ indicates if this person is the head of the household.\n",
    "- __Target:__ the label, which should be equal for all members in a household\n",
    "  \n",
    "When we make a model, we'll train on a household basis with the label for each household the poverty level of the head of household. The raw data contains a mix of both household and individual characteristics and for the individual data, we will have to find a way to aggregate this for each household. Some of the individuals belong to a household with no head of household which means that unfortunately we can't use this data for training. These issues with the data are completely typical of __real-world__ data and hence this problem is great preparation for the datasets you'll encounter in a data science job!  \n",
    "  \n",
    "### Metric\n",
    "Ultimately we want to build a machine learning model that can predict the integer poverty level of a household. Our predictions will be assessed by the __Macro F1 Score.__ You may be familiar with the standard F1 score for binary classification problems which is the harmonic mean of precision and recall:  \n",
    "  \n",
    "![image.png](attachment:image.png)\n",
    "  \n",
    "For mutli-class problems, we have to average the F1 scores for each class. The macro F1 score averages the F1 score for each class without taking into account label imbalances.  \n",
    "  \n",
    "![image-2.png](attachment:image-2.png)\n",
    "   \n",
    "In other words, the number of occurrences of each label does not figure into the calculation when using macro (while it does when using the \"weighted\" score). (For more information on the differences, look at the [Scikit-Learn Documention for F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) or this [Stack Exchange question and answers](https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin). If we want to assess our performance, we can use the code:  \n",
    "`from sklearn.metrics import f1_score`\n",
    "`f1_score(y_true, y_predicted, average = 'macro')`\n",
    "  \n",
    "For this problem, the labels are imbalanced, which makes it a little strange to use macro averaging for the evaluation metric, but that's a decision made by the organizers and not something we can change! In your own work, you want to be aware of label imbalances and choose a metric accordingly.\n",
    "  \n",
    "### Roadmap\n",
    "The end objective is a machine learning model that can predict the poverty level of a household. However, before we get carried away with modeling, it's important to understand the problem and data. Also, we want to evaluate numerous models before choosing one as the \"best\" and after building a model, we want to investigate the predictions. Our roadmap is therefore as follows:  \n",
    "  \n",
    "1. Understand the problem (we're almost there already)\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature engineering to create a dataset for machine learning\n",
    "4. Compare several baseline machine learning models\n",
    "5. Try more complex machine learning models\n",
    "6. Optimize the selected model\n",
    "7. Investigate model predictions in context of problem\n",
    "8. Draw conclusions and lay out next steps\n",
    "  \n",
    "The steps laid out above are iterative meaning that while we will go through them one at a time, we might go back to an earlier step and revisit some of our decisions. In general, data science is a non-linear pracice where we are constantly evaluating our past decisions and making improvements. In particular, feature engineering, modeling, and optimization are steps that we often repeat because we never know if we got them right the first time!  \n",
    "  \n",
    "## DeepL 번역\n",
    "또 다른 Kaggle 챌린지에 오신 것을 환영합니다! 코스타리카 가구 빈곤 수준 예측 콘테스트의 목표는 개인 및 가구 특성을 모두 사용하여 가구의 빈곤 수준을 예측할 수 있는 머신 러닝 모델을 개발하는 것입니다. 이 '선한 데이터 과학' 프로젝트는 사람들이 광고를 클릭하게 하는 것보다 사회에 더 유익한 일에 우리의 기술을 투입할 수 있는 기회를 제공합니다!  \n",
    "  \n",
    "이 노트북에서는 먼저 문제를 소개하고, 데이터 세트에 대한 철저한 탐색적 데이터 분석을 수행하고, 기능 엔지니어링 작업을 수행하고, 여러 머신러닝 모델을 시험해보고, 모델을 선택하고, 모델을 최적화하는 작업을 수행하고, 마지막으로 모델의 결과물을 검사하고 결론을 도출하는 등 완전한 머신러닝 솔루션의 과정을 안내합니다. 이 노트북으로 순위표의 정상에 오르지는 못하겠지만, 향후 머신 러닝 프로젝트를 위해 탄탄한 기초를 다질 수 있는 교육 도구로 사용할 수 있습니다. Kaggle 프로젝트를 통해 머신 러닝에 대해 많은 것을 배울 수 있지만, 리더보드의 최상위권에 오르는 데 사용된 몇 가지 전략은 모범 사례가 아니므로 여기서는 1등은 아니지만 매우 우수한 머신 러닝 솔루션을 구축하는 데 집중하겠습니다. Kaggle 프로젝트는 경연 대회이긴 하지만, 경연 대회로 위장한 '머신 러닝 교육'이라고 표현하는 것이 가장 적절하다고 생각합니다!\"  \n",
    "  \n",
    "이 작업에 대한 후속 작업을 원하신다면, 이 문제에 대한 [자동화된 피처 엔지니어링 사용에 대한 커널](https://www.kaggle.com/code/willkoehrsen/featuretools-for-good/notebook)과 [Featuretools](https://featuretools.alteryx.com/en/stable/#minute-quick-start)를 포함한 추가 작업이 있습니다(리더보드 점수가 약간 더 높습니다). (제 글쓰기 스타일과 설명이 마음에 드신다면, [Towards Data Science](https://williamkoehrsen.medium.com/)에 글을 쓰기도 합니다).  \n",
    "  \n",
    "### 문제 및 데이터 설명\n",
    "이 대회의 데이터는 train.csv와 test.csv의 두 가지 파일로 제공됩니다. 훈련 집합은 9557개의 행과 143개의 열로 구성되어 있고, 테스트 집합은 23856개의 행과 142개의 열로 구성되어 있습니다. 각 행은 __한 개인을__ 나타내고 각 열은 개인에게 고유하거나 개인의 가구에 대한 __특징을__ 나타냅니다. 훈련 집합에는 빈곤 수준을 1-4 척도로 나타내며 경쟁에 대한 레이블인 Target이라는 열이 하나 더 있습니다. 값이 1이면 가장 극심한 빈곤입니다.  \n",
    "  \n",
    "이것은 __다중 클래스 분류 머신 러닝 지도 학습 문제입니다:__  \n",
    "  \n",
    "- __지도 학습:__ 학습 데이터와 레이블이 함께 제공\n",
    "- __다중 클래스 분류:__ 레이블은 4개의 클래스가 있는 불연속형 값입니다.\n",
    "  \n",
    "### 목표\n",
    "목표는 __가구 수준에서__ 빈곤을 예측하는 것입니다. 각 개인의 고유한 특징과 가구에 대한 정보가 포함된 개인 수준의 데이터가 주어집니다. 이 작업을 위한 데이터 집합을 만들려면 각 가구에 대한 개별 데이터의 일부 집계를 수행해야 합니다. 또한 테스트 세트의 모든 개인에 대해 예측을 수행해야 하지만 \"가구주만 채점에 사용\"하므로 가구 단위로 빈곤을 예측하고자 합니다.\n",
    "\n",
    "__중요 참고 사항: 한 가구의 모든 구성원이 훈련 데이터에서 동일한 레이블을 가져야 하지만, 같은 가구의 개인이 다른 레이블을 갖는 오류가 발생할 수 있습니다. 이러한 경우 각 가구의 가장에 대한 레이블을 사용하라는 메시지가 표시되며, 이는 `parentesco1 == 1.0`인 행으로 식별할 수 있습니다.__ 노트북에서 이 문제를 해결하는 방법을 다룰 것입니다(자세한 내용은 [대회 메인 토론](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403)을 참조하세요).\n",
    "\n",
    "`목표` 값은 다음과 같이 빈곤 수준을 나타냅니다:\n",
    "\n",
    "`1 = 극심한 빈곤`  \n",
    "`2 = 중간 정도의 빈곤`  \n",
    "`3 = 취약한 가구`  \n",
    "`4 = 비취약 가구`  \n",
    "  \n",
    "143개의 모든 열에 대한 설명은 [대회 문서](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/data)에서 확인할 수 있지만, 몇 가지 주의해야 할 사항은 다음과 같습니다:  \n",
    "  \n",
    "- __Id:__ 각 개인에 대한 고유 식별자, 우리가 사용하는 기능이 아니어야 합니다!\n",
    "- __idhogar:__ 각 가구의 고유 식별자. 이 변수는 기능은 아니지만 한 가구의 모든 개인이 동일한 식별자를 갖게 되므로 가구별로 개인을 그룹화하는 데 사용됩니다.\n",
    "- __parentesco1:__ 세대주인지 여부를 나타냅니다.\n",
    "- __Target:__ 가구의 모든 구성원에게 동일한 레이블입니다.\n",
    "  \n",
    "모델을 만들 때 각 가구에 가구주의 빈곤 수준을 레이블로 지정하여 가구 단위로 훈련합니다. 원시 데이터에는 가구 및 개인 특성이 혼합되어 있으므로 개인 데이터의 경우 각 가구에 대해 이를 집계하는 방법을 찾아야 합니다. 일부 개인은 세대주가 없는 가구에 속해 있기 때문에 안타깝게도 이 데이터를 훈련에 사용할 수 없습니다. 이러한 데이터 문제는 __실세계__ 데이터에서 흔히 볼 수 있는 문제이므로 데이터 과학 업무에서 마주하게 될 데이터 집합에 대한 훌륭한 준비 과정입니다!  \n",
    "  \n",
    "### Metric\n",
    "궁극적으로 우리는 한 가구의 정수형 빈곤 수준을 예측할 수 있는 머신 러닝 모델을 구축하고자 합니다. __매크로 F1 점수로__ 예측을 평가할 것입니다. 이진 분류 문제에 대한 표준 F1 점수는 정확도와 재현율의 조화 평균으로, 익히 알고 계실 것입니다:  \n",
    "  \n",
    "![image.png](attachment:image.png)\n",
    "  \n",
    "다중 클래스 문제의 경우 각 클래스의 F1 점수의 평균을 구해야 합니다. 매크로 F1 점수는 라벨 불균형을 고려하지 않고 각 클래스의 F1 점수의 평균을 구합니다.  \n",
    "  \n",
    "![image-2.png](attachment:image-2.png)\n",
    "  \n",
    "즉, 매크로를 사용할 때는 각 레이블의 발생 횟수가 계산에 포함되지 않습니다(반면 \"가중치\" 점수를 사용할 때는 포함됨). (차이점에 대한 자세한 내용은 [F1 점수에 대한 Scikit-Learn 문서](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) 또는 이 [스택 교환 질문과 답변](https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin)을 참조하세요. 성능을 평가하고 싶다면 코드를 사용할 수 있습니다:  \n",
    "`from sklearn.metrics import f1_score`\n",
    "`f1_score(y_true, y_predicted, average = 'macro')`\n",
    "  \n",
    "이 문제의 경우 레이블이 불균형하기 때문에 평가 지표에 매크로 평균을 사용하는 것이 조금 이상하지만, 이는 주최 측에서 결정한 사항이며 저희가 변경할 수 있는 사항이 아닙니다! 자신의 작업에서 라벨 불균형을 인식하고 그에 따라 지표를 선택하는 것이 좋습니다.\n",
    "  \n",
    "### Roadmap\n",
    "최종 목표는 가구의 빈곤 수준을 예측할 수 있는 머신러닝 모델을 만드는 것입니다. 하지만 모델링에 몰두하기 전에 문제와 데이터를 이해하는 것이 중요합니다. 또한 수많은 모델을 평가한 후 '가장 좋은' 모델을 선택하고, 모델을 구축한 후에는 예측 결과를 조사하고자 합니다. 따라서 우리의 로드맵은 다음과 같습니다:  \n",
    "  \n",
    "1. 문제를 이해합니다(이미 거의 다 이해했습니다).\n",
    "2. 탐색적 데이터 분석\n",
    "3. 머신 러닝을 위한 데이터 세트 생성을 위한 기능 엔지니어링\n",
    "4. 여러 기준 머신 러닝 모델 비교\n",
    "5. 더 복잡한 머신러닝 모델 시도하기\n",
    "6. 선택한 모델 최적화하기\n",
    "7. 문제의 맥락에서 모델 예측 조사하기\n",
    "8. 결론 도출 및 다음 단계 계획\n",
    "  \n",
    "위에 설명한 단계는 반복적이기 때문에 한 번에 하나씩 진행하지만, 이전 단계로 돌아가서 일부 결정을 다시 검토할 수도 있습니다. 일반적으로 데이터 과학은 과거의 의사 결정을 지속적으로 평가하고 개선하는 비선형적인 프로세스입니다. 특히 기능 엔지니어링, 모델링 및 최적화는 처음에 제대로 했는지 알 수 없기 때문에 자주 반복하는 단계입니다!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "We have a pretty good grasp of the problem, so we'll move into the Exploratory Data Analysis (EDA) and feature engineering. For the EDA we'll examine any interesting anomalies, trends, correlations, or patterns that can be used for feature engineering and for modeling. We'll make sure to investigate our data both quantitatively (with statistics) and visually (with figures).  \n",
    "  \n",
    "Once we have a good grasp of the data and any potentially useful relationships, we can do some feature engineering (the most important part of the machine learning pipeline) and establish a baseline model. This won't get us to the top of the leaderboard, but it will provide a strong foundation to build on!  \n",
    "  \n",
    "With all that info in mind (don't worry if you haven't got all the details), let's get started!  \n",
    "  \n",
    "## DeepL 번역\n",
    "문제를 꽤 잘 파악했으므로 이제 탐색적 데이터 분석(EDA)과 피처 엔지니어링으로 넘어가겠습니다. EDA에서는 피처 엔지니어링과 모델링에 사용할 수 있는 흥미로운 이상 징후, 추세, 상관관계 또는 패턴을 조사할 것입니다. 데이터를 정량적(통계)으로, 그리고 시각적(그림)으로 조사할 것입니다.  \n",
    "  \n",
    "데이터와 잠재적으로 유용한 관계를 잘 파악하고 나면 머신 러닝 파이프라인에서 가장 중요한 부분인 피처 엔지니어링을 수행하고 기준 모델을 설정할 수 있습니다. 이렇게 한다고 해서 순위표의 정상에 오를 수는 없지만, 그 위에 구축할 수 있는 강력한 토대를 제공할 수 있습니다!  \n",
    "  \n",
    "이 모든 정보를 염두에 두고(모든 세부 사항을 파악하지 못했더라도 걱정하지 마세요) 시작해 봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "We'll use a familiar stack of data science libraries: Pandas, numpy, matplotlib, seaborn, and eventually sklearn for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Set a few plotting defaults\n",
    "%matplotlib inline\n",
    "# plt.style.use('fivethirtyeight')\n",
    "# plt.rcParams['font.size'] = 18\n",
    "# plt.rcParams['patch.edgecolor'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0     0  ...          100    1849               1        100             0   \n",
       "1     0  ...          144    4489               1        144             0   \n",
       "2     0  ...          121    8464               1          0             0   \n",
       "3     0  ...           81     289              16        121             4   \n",
       "4     0  ...          121    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0         1.000000            0.0      100.0   1849       4  \n",
       "1         1.000000           64.0      144.0   4489       4  \n",
       "2         0.250000           64.0      121.0   8464       4  \n",
       "3         1.777778            1.0      121.0    289       4  \n",
       "4         1.777778            1.0      121.0   1369       4  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read in Data and Look at Summary information\n",
    "\n",
    "# pd.options.display.max_columns = 150\n",
    "\n",
    "## Read in data\n",
    "train = pd.read_csv('./input/004_costa-rican-household-poverty-prediction/train.csv')\n",
    "test = pd.read_csv('./input/004_costa-rican-household-poverty-prediction/test.csv')\n",
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
