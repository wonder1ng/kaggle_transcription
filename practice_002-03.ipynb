{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[이유한님] 캐글 코리아 캐글 스터디 커널 커리큘럼](https://kaggle-kr.tistory.com/32)  \n",
    "[2nd level. Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)  \n",
    "[XGBoost CV (LB .284)](https://www.kaggle.com/code/aharless/xgboost-cv-lb-284)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [olivier's script](https://www.kaggle.com/code/ogrellier/xgb-classifier-upsampling-lb-0-283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n",
    "#       I will get lots of information to make my own judgment. You should probably\n",
    "#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend initially setting `MAX_ROUNDS` fairly high and using `OPTIMIZE_ROUNDS` to get an idea of the appropriate number of rounds (which, in my judgment, should be close to the maximum value of `best_ntree_limit` among all folds, maybe even a bit higher if your model is adequately regularized...or alternatively, you could set `verbose=True` and look at the details to try to find a number of rounds that works well for all folds). Then I  ould turn off `OPTIMIZE_ROUNDS` and set `MAX_ROUNDS` to the appropraite number of total rounds.  \n",
    "  \n",
    "The problem with \"early stopping\" by choosing the best round for each fold is that it overfits to the validation data. It's therefore liable not to produce the optimal model for predicting test data, and if it's used to produce validation data for stacking/ensembling with other models, it would cause this one to have too much weight in the ensemble. Another possibility (and the default for XGBoost, it seems) is to use the round where the early stop actually happens (with the lag that verifies lack of improvement) rather than the best round. That solves the overfitting problem (provided the lag is long enough), but so far it doesn't seem to have helped. (I got a worse validation score with 20-round early stopping per fold than with a constant number of rounds for all folds, so the early stopping actually seemed to underfit.)  \n",
    "  \n",
    "__DeepL 번역__\n",
    "처음에는 `MAX_ROUNDS`를 상당히 높게 설정하고 `OPTIMIZE_ROUNDS`를 사용하여 적절한 라운드 수를 파악하는 것이 좋습니다(제 판단으로는 모든 폴드 중 `best_ntree_limit`의 최대 값에 가까워야 하며, 모델이 적절하게 정규화된 경우 약간 더 높을 수도 있습니다... 또는 `verbose=True`를 설정하고 세부 사항을 살펴 모든 폴드에 잘 맞는 라운드 수를 찾을 수 있습니다). 그런 다음 `OPTIMIZE_ROUNDS`를 끄고 `MAX_ROUNDS`를 적절한 총 라운드 수로 설정합니다.  \n",
    "  \n",
    "각 폴드에 가장 적합한 라운드를 선택하여 \"early stopping\"하는 경우의 문제점은 유효성 검사 데이터에 과도하게 적합하다는 것입니다. 따라서 테스트 데이터 예측을 위한 최적의 모델을 생성하지 못할 수 있으며, 다른 모델과 stacking/ensembling을 위한 검증 데이터를 생성하는 데 사용하면 이 모델이 앙상블에서 너무 많은 가중치를 갖게 될 수 있습니다. 또 다른 가능성(그리고 XGBoost의 기본값인 것 같습니다)은 최상의 라운드가 아니라 실제로 조기 정지가 발생하는 라운드(개선 부족을 확인하는 지연이 있는 라운드)를 사용하는 것입니다. 이렇게 하면 과적합 문제를 해결할 수 있지만(지연이 충분히 길다면) 지금까지는 도움이 되지 않는 것 같습니다. (모든 폴드에 대해 일정한 라운드 수를 적용하는 것보다 폴드당 20라운드 조기 정지를 적용했을 때 더 나쁜 검증 점수를 받았기 때문에 실제로 조기 정지가 과적합한 것으로 보입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit   # jit( just-in-time) 컴파일러로써 데코레이트한 함수가 파이썬을 bytecode로 읽어서 빠르다 한다.\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true) # np.asarray: 기본적으로 copy되지 않고 같은 메모리를 사용.\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i*delta\n",
    "        delta += 1-y_i\n",
    "    gini = 1-2*gini/(ntrue*(n-ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from olivier's kernel\n",
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1+noise_level*np.random.randn(len(series)))\n",
    "\n",
    "def target_encide(trn_series=None,  # Revised to encode validation series\n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    (위 링크 연결 안 됨)\n",
    "    trn_series: training categorical feature as a pd.Series\n",
    "    tst_series: test categorical feature as a pd.Series\n",
    "    target: target data as a pd.Series\n",
    "    min_samples_leaf (int): minimum samples to take category average into account\n",
    "    smoothing (int): smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean', 'count'])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1+np.exp(-(averages['count'] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1-smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tran_series.name,\n",
    "        how='left')['average'].rename(trn_series.name+'_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index sp restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_trn_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name+'_mean').fillna(prior)\n",
    "    # pd.merge dose not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/aharless/xgboost-cv-lb-284"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
