{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[이유한님] 캐글 코리아 캐글 스터디 커널 커리큘럼](https://kaggle-kr.tistory.com/32)\n",
    "\n",
    "[Statoil/C-CORE Iceberg Classifier Challenge](https://www.kaggle.com/c/statoil-iceberg-classifier-challenge)\n",
    "\n",
    "[Keras+TF LB 0.18](https://www.kaggle.com/code/wvadim/keras-tf-lb-0-18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction** This is actually my first public kernel, so i hope it will be useful for someone.\n",
    "\n",
    "Before you read the notebook, it is immportant to know that this notebook is a compilation of already existing notebooks and some model modifications Here is list of notebooks:\n",
    "\n",
    "- Data analysis - https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python\n",
    "- Image conversion, Network architecture - https://www.kaggle.com/tivigovidiu/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "- Some ideas - https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "- Code for conversion to image provided by MadScientist but i don't know which kernel it is.\n",
    "\n",
    "Before running the model it is good idea to run thgrough kernels mentioned here and upvote them.\n",
    "\n",
    "**Comments** I've executed this code on my machine with 1080 TI and it may be pretty slow if you have low-end GPU or CPU\n",
    "\n",
    "It is also important that i don't know how to execute code in the notebook with GPU, since keras is not freeing memory after model training, so train results here may be uncomplete.\n",
    "\n",
    "I am also not sure about random seed initialization and haven't checked it, so maybe your results may differ from mine.\n",
    "\n",
    "I am also sorry for a WinAPI style functions with 10+ arguments, but this solutin was made less than in a one day and basically my second solution. If someone is able to rewrite it in a normal style i will appreciate that, so feel free to fork and rewrite.\n",
    "\n",
    "**DeepL 번역**  \n",
    "**소개** 사실 제가 처음으로 공개하는 커널이기 때문에 누군가에게 도움이 되길 바랍니다.\n",
    "\n",
    "노트북을 읽기 전에 이 노트북은 이미 존재하는 노트북을 편집하고 일부 모델을 수정한 것임을 알아두는 것이 중요합니다. 다음은 노트북 목록입니다:\n",
    "\n",
    "- 데이터 분석 - https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python\n",
    "- 이미지 변환, 네트워크 아키텍처 - https://www.kaggle.com/tivigovidiu/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "- 몇 가지 아이디어 - https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "- MadScientist에서 이미지로 변환하는 코드를 제공했지만 어떤 커널인지 모르겠습니다.\n",
    "\n",
    "모델을 실행하기 전에 여기에 언급 된 커널을 실행하고 업보트하는 것이 좋습니다.\n",
    "\n",
    "**첨언** 1080 TI가 장착 된 컴퓨터에서이 코드를 실행했으며 저사양 GPU 또는 CPU가있는 경우 상당히 느릴 수 있습니다.\n",
    "\n",
    "또한 모델 훈련 후 케라스가 메모리를 해제하지 않기 때문에 GPU가있는 노트북에서 코드를 실행하는 방법을 모르기 때문에 여기서 훈련 결과가 불완전 할 수 있습니다.\n",
    "\n",
    "또한 무작위 시드 초기화에 대해 잘 모르겠고 확인하지 않았으므로 결과가 저와 다를 수 있습니다.\n",
    "\n",
    "또한 10 개 이상의 인수가있는 WinAPI 스타일 함수에 대해 죄송하지만이 솔루션은 하루도 채 걸리지 않고 기본적으로 두 번째 솔루션입니다. 누군가가 정상적인 스타일로 다시 작성할 수 있다면 감사 할 것이므로 자유롭게 포크하고 다시 작성하십시오.\n",
    "\n",
    "Translated with DeepL.com (free version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization\n",
    "import numpy as np\n",
    "np.random.seed(98643)\n",
    "import tensorflow as tf\n",
    "# tf.set_random_seed(683)\n",
    "tf.random.set_seed(683) # 함수 변경\n",
    "# Uncomment this to hide TF warnings about allocation\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# An image clearing dependencies\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral, denoise_wavelet, estimate_sigma, denoise_tv_bregman, denoise_nl_means)\n",
    "# denoise_tv_chambolle: 총 변동(Total Variation) 기반 필터로 이미지 노이즈 제거\n",
    "# denoise_bilateral:    양방향 필터링(Bilateral Filtering)으로 이미지의 엣지 보존 노이즈 제거\n",
    "# denoise_wavelet:      웨이블릿 변환(Wavelet Denoising)으로 노이즈 제거\n",
    "# estimate_sigma:       노이즈 표준편차 추정\n",
    "# denoise_tv_bregman:   Bregman 총 변동 기반 노이즈 제거법. 이미지 윤관 유지하며 노이즈 제거\n",
    "# denoise_nl_means:     비국소적 평균(Non-Local Means) 필터는 유사 패턴 픽셀들의 가중 평균으로 대체하여 노이즈 제거\n",
    "\n",
    "from skimage.filters import gaussian    # 이미지를 부드럽게 만들거나 블러 적용\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Data reading and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Training part\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, GlobalAveragePooling2D, Lambda\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.merge import Concatenate\n",
    "from keras.layers import BatchNormalization, Concatenate    # 버전 차이\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # tf에서 호출해야지만 import 됨\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, some data preprocessing is required.\n",
    "\n",
    "The basic idea is that images, that provided in a dataset are very noisy and if we will get rid of granular noise, we will be able to predict better and construct noisy dataset by our own.\n",
    "\n",
    "It is also interesting to train a denoising autoencoder on dataset in order to extract some global features that may be used further on model training.\n",
    "\n",
    "**DeepL 번역**  \n",
    "우선, 약간의 데이터 전처리가 필요합니다.\n",
    "\n",
    "기본 아이디어는 데이터 세트에서 제공되는 이미지에는 노이즈가 매우 많기 때문에 세분화된 노이즈를 제거하면 더 나은 예측이 가능하고 노이즈가 적은 데이터 세트를 자체적으로 구성할 수 있다는 것입니다.\n",
    "\n",
    "모델 훈련에 추가로 사용할 수 있는 글로벌 특징을 추출하기 위해 데이터 세트에서 노이즈 제거 자동 인코더를 훈련하는 것도 흥미롭습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate data to an image format\n",
    "def color_composite(data):\n",
    "    rgb_arrays = []\n",
    "    for i, row in data.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 / band_2\n",
    "\n",
    "        r = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n",
    "        \n",
    "        g = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n",
    "\n",
    "        b = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        rgb_arrays.append(rgb)\n",
    "    \n",
    "    return np.array(rgb_arrays)\n",
    "\n",
    "def denoise(X, weight, multichannel):\n",
    "    # return np.asarray([denoise_tv_chambolle(item, weight=weight, multichannel=multichannel) for item in X])\n",
    "    return np.asarray([denoise_tv_chambolle(item, weight=weight, channel_axis=multichannel) for item in X]) # 인자명 변경된 듯\n",
    "\n",
    "def smooth(X, sigma):\n",
    "    return np.asarray([gaussian(item, sigma=sigma) for item in X])\n",
    "\n",
    "def grayscale(X):\n",
    "    return np.asarray([rgb2gray(item) for item in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"./input/005_statoil-iceberg-classifier-challenge/train.json\")\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "train_all = True\n",
    "\n",
    "# These are train flags that required to train model more efficiently and\n",
    "# select proper model parameters\n",
    "train_b = True or train_all\n",
    "train_img = True or train_all\n",
    "train_total = True or train_all\n",
    "predict_submission = True or train_all\n",
    "\n",
    "clean_all = False\n",
    "clean_b = False or clean_all\n",
    "clean_img = False or clean_all\n",
    "\n",
    "load_all = False\n",
    "load_b = False or load_all\n",
    "load_img = False or load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(frame, labeled, smooth_rgb=0.2, smooth_gray=0.5,\n",
    "                   weight_rgb=0.05, weight_gray=0.05):\n",
    "    band_1, band_2, images = frame['band_1'].values, frame['band_2'].values, color_composite(frame)\n",
    "    to_arr = lambda x: np.asarray([np.asarray(item) for item in x])\n",
    "    band_1 = to_arr(band_1)\n",
    "    band_2 = to_arr(band_2)\n",
    "    band_3 = (band_1 + band_2) / 2\n",
    "    gray_reshape = lambda x: np.asarray([item.reshape(75, 75) for item in x])\n",
    "    # Make a picture format from flat vector\n",
    "    band_1 = gray_reshape(band_1)\n",
    "    band_2 = gray_reshape(band_2)\n",
    "    band_3 = gray_reshape(band_3)\n",
    "    print('Denoising and reshaping')\n",
    "    if train_b and clean_b:\n",
    "        # Smooth and denoise data\n",
    "        band_1 = smooth(denoise(band_1, weight_gray, False), smooth_gray)\n",
    "        print('Gray 1 done')\n",
    "        band_2 = smooth(denoise(band_2, weight_gray, False), smooth_gray)\n",
    "        print('Gray 2 done')\n",
    "        band_3 = smooth(denoise(band_3, weight_gray, False), smooth_gray)\n",
    "        print('Gray 3 done')\n",
    "    if train_img and clean_img:\n",
    "        images = smooth(denoise(images, weight_rgb, True), smooth_rgb)\n",
    "    print('RGB done')\n",
    "    tf_reshape = lambda x: np.asarray([item.reshape(75, 75, 1) for item in x])\n",
    "    band_1 = tf_reshape(band_1)\n",
    "    band_2 = tf_reshape(band_2)\n",
    "    band_3 = tf_reshape(band_3)\n",
    "    # images = tf_reshape(images)\n",
    "    band = np.concatenate([band_1, band_2, band_3], axis=3)\n",
    "    if labeled:\n",
    "        y = np.array(frame[\"is_iceberg\"])\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    return y, band, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_b, X_images = create_dataset(train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting some random images to check how cleaning works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(200, figsize=(15, 15))\n",
    "random_indicies = np.random.choice(range(len(X_images)), 9, False)\n",
    "subset = X_images[random_indicies]\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "band_1_x = train['band_1'].values\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = np.asarray([np.asarray(item).reshape(75, 75) for item in subset])\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = denoise(np.asarray([np.asarray(item).reshape(75, 75) for item in subset]), 0.05, False)\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = smooth(denoise(np.asarray(\n",
    "    [np.asarray(item).reshape(75, 75) for item in subset]), 0.05, False), 0.5)\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A few words about model**\n",
    "\n",
    "The model itself consists of 3 convolutional neural networks. Two basic networks and one combined. The idea is to train two basic networks on different data representations and after that, using trained convolutional layers in combination to train common network.\n",
    "\n",
    "Architecture for these networks is taken from notebook mentioned in the vere beginning.\n",
    "\n",
    "For training i'm using 3 datasets, 1 that network sees only once and default keras val split for model selection.\n",
    "\n",
    "**DeepL 번역**  \n",
    "\n",
    "모델 자체는 3개의 컨볼루션 신경망으로 구성됩니다. 두 개의 기본 네트워크와 하나의 결합 네트워크. 서로 다른 데이터 표현에 대해 두 개의 기본 네트워크를 훈련한 다음, 훈련된 컨볼루션 레이어를 조합하여 공통 네트워크를 훈련하는 것이 아이디어입니다.\n",
    "\n",
    "이러한 네트워크의 아키텍처는 앞부분에서 언급한 노트북에서 가져왔습니다.\n",
    "\n",
    "훈련에는 3개의 데이터 세트, 네트워크가 한 번만 보는 데이터 세트, 모델 선택을 위한 기본 케라스 값 분할을 사용하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_notebook(lr, decay, channels, relu_type='reklu'):\n",
    "    # angle variable defines if we should use angle parameter or ignore it\n",
    "    input_1 = Input(shape=(75, 785, channels))\n",
    "\n",
    "    fcnn = Conv2D(32, kernel_size=(3, 3), activatio=relu_type)(BatchNormalization()(input_1))\n",
    "    fcnn = MaxPooling2D((3, 3))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(64, kernel_size=(3, 3), activatio=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activatio=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activatio=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = BatchNormalization()(fcnn)\n",
    "    fcnn = Flatten()(fcnn)\n",
    "    local_input = input_1\n",
    "    partial_model = Model(input_1, fcnn)\n",
    "    dense = Dropout(0.2)(fcnn)\n",
    "    dense = Dense(256, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(128, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(64, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    # For some reason I've decided not to normaliuze angle data\n",
    "    output = Dense(1, activation=\"sigmoid\")(dense)\n",
    "    model = Model(local_input, output)\n",
    "    # optimizer = Adam(lr=lr, decay=decay)    # 인자명 변경됨.\n",
    "    optimizer = Adam(learning_rate=lr, decay=decay)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model, partial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/wvadim/keras-tf-lb-0-18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
