{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[이유한님] 캐글 코리아 캐글 스터디 커널 커리큘럼](https://kaggle-kr.tistory.com/32)\n",
    "\n",
    "[Statoil/C-CORE Iceberg Classifier Challenge](https://www.kaggle.com/c/statoil-iceberg-classifier-challenge)\n",
    "\n",
    "[Keras+TF LB 0.18](https://www.kaggle.com/code/wvadim/keras-tf-lb-0-18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction** This is actually my first public kernel, so i hope it will be useful for someone.\n",
    "\n",
    "Before you read the notebook, it is immportant to know that this notebook is a compilation of already existing notebooks and some model modifications Here is list of notebooks:\n",
    "\n",
    "- Data analysis - https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python\n",
    "- Image conversion, Network architecture - https://www.kaggle.com/tivigovidiu/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "- Some ideas - https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "- Code for conversion to image provided by MadScientist but i don't know which kernel it is.\n",
    "\n",
    "Before running the model it is good idea to run thgrough kernels mentioned here and upvote them.\n",
    "\n",
    "**Comments** I've executed this code on my machine with 1080 TI and it may be pretty slow if you have low-end GPU or CPU\n",
    "\n",
    "It is also important that i don't know how to execute code in the notebook with GPU, since keras is not freeing memory after model training, so train results here may be uncomplete.\n",
    "\n",
    "I am also not sure about random seed initialization and haven't checked it, so maybe your results may differ from mine.\n",
    "\n",
    "I am also sorry for a WinAPI style functions with 10+ arguments, but this solutin was made less than in a one day and basically my second solution. If someone is able to rewrite it in a normal style i will appreciate that, so feel free to fork and rewrite.\n",
    "\n",
    "**DeepL 번역**  \n",
    "**소개** 사실 제가 처음으로 공개하는 커널이기 때문에 누군가에게 도움이 되길 바랍니다.\n",
    "\n",
    "노트북을 읽기 전에 이 노트북은 이미 존재하는 노트북을 편집하고 일부 모델을 수정한 것임을 알아두는 것이 중요합니다. 다음은 노트북 목록입니다:\n",
    "\n",
    "- 데이터 분석 - https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python\n",
    "- 이미지 변환, 네트워크 아키텍처 - https://www.kaggle.com/tivigovidiu/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "- 몇 가지 아이디어 - https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "- MadScientist에서 이미지로 변환하는 코드를 제공했지만 어떤 커널인지 모르겠습니다.\n",
    "\n",
    "모델을 실행하기 전에 여기에 언급 된 커널을 실행하고 업보트하는 것이 좋습니다.\n",
    "\n",
    "**첨언** 1080 TI가 장착 된 컴퓨터에서이 코드를 실행했으며 저사양 GPU 또는 CPU가있는 경우 상당히 느릴 수 있습니다.\n",
    "\n",
    "또한 모델 훈련 후 케라스가 메모리를 해제하지 않기 때문에 GPU가있는 노트북에서 코드를 실행하는 방법을 모르기 때문에 여기서 훈련 결과가 불완전 할 수 있습니다.\n",
    "\n",
    "또한 무작위 시드 초기화에 대해 잘 모르겠고 확인하지 않았으므로 결과가 저와 다를 수 있습니다.\n",
    "\n",
    "또한 10 개 이상의 인수가있는 WinAPI 스타일 함수에 대해 죄송하지만이 솔루션은 하루도 채 걸리지 않고 기본적으로 두 번째 솔루션입니다. 누군가가 정상적인 스타일로 다시 작성할 수 있다면 감사 할 것이므로 자유롭게 포크하고 다시 작성하십시오.\n",
    "\n",
    "Translated with DeepL.com (free version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization\n",
    "import numpy as np\n",
    "np.random.seed(98643)\n",
    "import tensorflow as tf\n",
    "# tf.set_random_seed(683)\n",
    "tf.random.set_seed(683) # 함수 변경\n",
    "# Uncomment this to hide TF warnings about allocation\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# An image clearing dependencies\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral, denoise_wavelet, estimate_sigma, denoise_tv_bregman, denoise_nl_means)\n",
    "# denoise_tv_chambolle: 총 변동(Total Variation) 기반 필터로 이미지 노이즈 제거\n",
    "# denoise_bilateral:    양방향 필터링(Bilateral Filtering)으로 이미지의 엣지 보존 노이즈 제거\n",
    "# denoise_wavelet:      웨이블릿 변환(Wavelet Denoising)으로 노이즈 제거\n",
    "# estimate_sigma:       노이즈 표준편차 추정\n",
    "# denoise_tv_bregman:   Bregman 총 변동 기반 노이즈 제거법. 이미지 윤관 유지하며 노이즈 제거\n",
    "# denoise_nl_means:     비국소적 평균(Non-Local Means) 필터는 유사 패턴 픽셀들의 가중 평균으로 대체하여 노이즈 제거\n",
    "\n",
    "from skimage.filters import gaussian    # 이미지를 부드럽게 만들거나 블러 적용\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Data reading and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Training part\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, GlobalAveragePooling2D, Lambda\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.merge import Concatenate\n",
    "from keras.layers import BatchNormalization, Concatenate    # 버전 차이\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # tf에서 호출해야지만 import 됨\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, some data preprocessing is required.\n",
    "\n",
    "The basic idea is that images, that provided in a dataset are very noisy and if we will get rid of granular noise, we will be able to predict better and construct noisy dataset by our own.\n",
    "\n",
    "It is also interesting to train a denoising autoencoder on dataset in order to extract some global features that may be used further on model training.\n",
    "\n",
    "**DeepL 번역**  \n",
    "우선, 약간의 데이터 전처리가 필요합니다.\n",
    "\n",
    "기본 아이디어는 데이터 세트에서 제공되는 이미지에는 노이즈가 매우 많기 때문에 세분화된 노이즈를 제거하면 더 나은 예측이 가능하고 노이즈가 적은 데이터 세트를 자체적으로 구성할 수 있다는 것입니다.\n",
    "\n",
    "모델 훈련에 추가로 사용할 수 있는 글로벌 특징을 추출하기 위해 데이터 세트에서 노이즈 제거 자동 인코더를 훈련하는 것도 흥미롭습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate data to an image format\n",
    "def color_composite(data):\n",
    "    rgb_arrays = []\n",
    "    for i, row in data.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 / band_2\n",
    "\n",
    "        r = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n",
    "        \n",
    "        g = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n",
    "\n",
    "        b = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        rgb_arrays.append(rgb)\n",
    "    \n",
    "    return np.array(rgb_arrays)\n",
    "\n",
    "def denoise(X, weight, multichannel):\n",
    "    # return np.asarray([denoise_tv_chambolle(item, weight=weight, multichannel=multichannel) for item in X])\n",
    "    return np.asarray([denoise_tv_chambolle(item, weight=weight, channel_axis=multichannel) for item in X]) # 인자명 변경된 듯\n",
    "\n",
    "def smooth(X, sigma):\n",
    "    return np.asarray([gaussian(item, sigma=sigma) for item in X])\n",
    "\n",
    "def grayscale(X):\n",
    "    return np.asarray([rgb2gray(item) for item in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"./input/005_statoil-iceberg-classifier-challenge/train.json\")\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "train_all = True\n",
    "\n",
    "# These are train flags that required to train model more efficiently and\n",
    "# select proper model parameters\n",
    "train_b = True or train_all\n",
    "train_img = True or train_all\n",
    "train_total = True or train_all\n",
    "predict_submission = True or train_all\n",
    "\n",
    "clean_all = False\n",
    "clean_b = False or clean_all\n",
    "clean_img = False or clean_all\n",
    "\n",
    "load_all = False\n",
    "load_b = False or load_all\n",
    "load_img = False or load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(frame, labeled, smooth_rgb=0.2, smooth_gray=0.5,\n",
    "                   weight_rgb=0.05, weight_gray=0.05):\n",
    "    band_1, band_2, images = frame['band_1'].values, frame['band_2'].values, color_composite(frame)\n",
    "    to_arr = lambda x: np.asarray([np.asarray(item) for item in x])\n",
    "    band_1 = to_arr(band_1)\n",
    "    band_2 = to_arr(band_2)\n",
    "    band_3 = (band_1 + band_2) / 2\n",
    "    gray_reshape = lambda x: np.asarray([item.reshape(75, 75) for item in x])\n",
    "    # Make a picture format from flat vector\n",
    "    band_1 = gray_reshape(band_1)\n",
    "    band_2 = gray_reshape(band_2)\n",
    "    band_3 = gray_reshape(band_3)\n",
    "    print('Denoising and reshaping')\n",
    "    if train_b and clean_b:\n",
    "        # Smooth and denoise data\n",
    "        band_1 = smooth(denoise(band_1, weight_gray, False), smooth_gray)\n",
    "        print('Gray 1 done')\n",
    "        band_2 = smooth(denoise(band_2, weight_gray, False), smooth_gray)\n",
    "        print('Gray 2 done')\n",
    "        band_3 = smooth(denoise(band_3, weight_gray, False), smooth_gray)\n",
    "        print('Gray 3 done')\n",
    "    if train_img and clean_img:\n",
    "        images = smooth(denoise(images, weight_rgb, True), smooth_rgb)\n",
    "    print('RGB done')\n",
    "    tf_reshape = lambda x: np.asarray([item.reshape(75, 75, 1) for item in x])\n",
    "    band_1 = tf_reshape(band_1)\n",
    "    band_2 = tf_reshape(band_2)\n",
    "    band_3 = tf_reshape(band_3)\n",
    "    # images = tf_reshape(images)\n",
    "    band = np.concatenate([band_1, band_2, band_3], axis=3)\n",
    "    if labeled:\n",
    "        y = np.array(frame[\"is_iceberg\"])\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    return y, band, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_b, X_images = create_dataset(train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting some random images to check how cleaning works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(200, figsize=(15, 15))\n",
    "random_indicies = np.random.choice(range(len(X_images)), 9, False)\n",
    "subset = X_images[random_indicies]\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "band_1_x = train['band_1'].values\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = np.asarray([np.asarray(item).reshape(75, 75) for item in subset])\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = denoise(np.asarray([np.asarray(item).reshape(75, 75) for item in subset]), 0.05, False)\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(202, figsize=(15, 15))\n",
    "subset = np.asarray(band_1_x)[random_indicies]\n",
    "subset = smooth(denoise(np.asarray(\n",
    "    [np.asarray(item).reshape(75, 75) for item in subset]), 0.05, False), 0.5)\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3, 3, i + 1)\n",
    "    ax.imshow(subset[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A few words about model**\n",
    "\n",
    "The model itself consists of 3 convolutional neural networks. Two basic networks and one combined. The idea is to train two basic networks on different data representations and after that, using trained convolutional layers in combination to train common network.\n",
    "\n",
    "Architecture for these networks is taken from notebook mentioned in the vere beginning.\n",
    "\n",
    "For training i'm using 3 datasets, 1 that network sees only once and default keras val split for model selection.\n",
    "\n",
    "**DeepL 번역**  \n",
    "\n",
    "모델 자체는 3개의 컨볼루션 신경망으로 구성됩니다. 두 개의 기본 네트워크와 하나의 결합 네트워크. 서로 다른 데이터 표현에 대해 두 개의 기본 네트워크를 훈련한 다음, 훈련된 컨볼루션 레이어를 조합하여 공통 네트워크를 훈련하는 것이 아이디어입니다.\n",
    "\n",
    "이러한 네트워크의 아키텍처는 앞부분에서 언급한 노트북에서 가져왔습니다.\n",
    "\n",
    "훈련에는 3개의 데이터 세트, 네트워크가 한 번만 보는 데이터 세트, 모델 선택을 위한 기본 케라스 값 분할을 사용하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_notebook(lr, decay, channels, relu_type='reklu'):\n",
    "    # angle variable defines if we should use angle parameter or ignore it\n",
    "    input_1 = Input(shape=(75, 75, channels))\n",
    "\n",
    "    fcnn = Conv2D(32, kernel_size=(3, 3), activation=relu_type)(\n",
    "        BatchNormalization()(input_1))\n",
    "    fcnn = MaxPooling2D((3, 3))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(64, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = Conv2D(128, kernel_size=(3, 3), activation=relu_type)(fcnn)\n",
    "    fcnn = MaxPooling2D((2, 2), strides=(2, 2))(fcnn)\n",
    "    fcnn = Dropout(0.2)(fcnn)\n",
    "    fcnn = BatchNormalization()(fcnn)\n",
    "    fcnn = Flatten()(fcnn)\n",
    "    local_input = input_1\n",
    "    partial_model = Model(input_1, fcnn)\n",
    "    dense = Dropout(0.2)(fcnn)\n",
    "    dense = Dense(256, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(128, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    dense = Dense(64, activation=relu_type)(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    # For some reason I've decided not to normaliuze angle data\n",
    "    output = Dense(1, activation=\"sigmoid\")(dense)\n",
    "    model = Model(local_input, output)\n",
    "    # optimizer = Adam(lr=lr, decay=decay)    # 인자명 변경됨.\n",
    "    optimizer = Adam(learning_rate=lr, decay=decay)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model, partial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model(m_b, m_img, lr, decay):\n",
    "    input_b = Input(shape=(75, 75, 3))\n",
    "    input_img = Input(shape=(75, 75, 3))\n",
    "\n",
    "    # I've never tested non-trainable source models tho\n",
    "    # for layer in m_b.layers:\n",
    "    #     layer.trainable = False\n",
    "    # for layer in m_img.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    m1 = m_b(input_b)\n",
    "    m2 = m_img(input_img)\n",
    "\n",
    "    # So, combine models and train perceptron based on that\n",
    "    # The iteresting idea is to use XGB for this task, but i actually hate this method\n",
    "    common = Concatenate()([m1, m2])\n",
    "    common = BatchNormalization()(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Dense(1024, activation='relu')(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    common = Dense(512, activation='relu')(common)\n",
    "    common = Dropout(0.3)(common)\n",
    "    output = Dense(1, activation='sigmoid')(common)\n",
    "    model = Model([input_b, input_img], output)\n",
    "    # optimizer = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay)   # 인자명 변경\n",
    "    optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=decay)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_flow_multi_inputs(I1, I2, y, batch_size):\n",
    "    gen1 = ImageDataGenerator(horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              width_shift_range=0.,\n",
    "                              height_shift_range=0.,\n",
    "                              channel_shift_range=0.,\n",
    "                              zoom_range=0.2,\n",
    "                              rotation_range=10)\n",
    "    gen2 = ImageDataGenerator(horizontal_flip=True,\n",
    "                              vertical_flip=True,\n",
    "                              width_shift_range=0.,\n",
    "                              height_shift_range=0.,\n",
    "                              channel_shift_range=0.,\n",
    "                              zoom_range=0.2,\n",
    "                              rotation_range=10)\n",
    "    genI1 = gen1.flow(I1, y, batch_size=batch_size, seed=57, shuffle=False)\n",
    "    genI2 = gen2.flow(I1, I2, batch_size=batch_size, seed=57, shuffle=False)\n",
    "    while True:\n",
    "        # I1i = genI1.next()\n",
    "        # I2i = genI2.next()\n",
    "        # next -> __next__\n",
    "        I1i = genI1.__next__()\n",
    "        I2i = genI2.__next__()\n",
    "        # print(I1i[0].shape)\n",
    "        np.testing.assert_array_equal(I2i[0], I1i[0])\n",
    "        # yield [I1i[0], I2i[1], I1i[1]]\n",
    "        # 오류문: ValueError: When passing a Python generator to a Keras model, the generator must return a tuple, either (input,) or (inputs, targets) or (inputs, targets, sample_weights).\n",
    "        yield ((I1i[0], I2i[1]), I1i[1])  # 튜플로 반환해야만 함. 튜플로 X 묶음(리스트로 묶으면 자료형 오류 발생)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, epochs, checkpoint_name, X_train, y_train, val_data, verbose=2):\n",
    "    # callbacks = [ModelCheckpoint(checkpoint_name, save_best_only=True, monitor='val_loss')]\n",
    "    callbacks = [ModelCheckpoint(checkpoint_name+\".keras\", save_best_only=True, monitor='val_loss')]\n",
    "    datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 width_shift_range=0.,\n",
    "                                 height_shift_range=0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range=0.2,\n",
    "                                 rotation_range=10)\n",
    "    x_test, y_test = val_data\n",
    "    try:\n",
    "        # fit_generator -> fit\n",
    "        model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                            # steps_per_epoch=len(X_train) / batch_size,    # 실수로 타입 오류 발생\n",
    "                            steps_per_epoch=round(len(X_train) / batch_size),\n",
    "                            validation_data=(x_test, y_test), verbose=1,\n",
    "                            callbacks=callbacks)\n",
    "    except KeyboardInterrupt:\n",
    "        if verbose > 0:\n",
    "            print('Interrupted')\n",
    "    if verbose > 0:\n",
    "        print('Loading model')\n",
    "    model.load_weights(filepath=checkpoint_name+\".keras\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a particular model\n",
    "def gen_model_weights(lr, decay, channels, relu, batch_size, epochs, path_name, data, verbose=2):\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = data\n",
    "    model, partial_model = get_model_notebook(lr, decay, channels, relu)\n",
    "    model = train_model(model, batch_size, epochs, path_name,\n",
    "                        X_train, y_train, (X_test, y_test), verbose=verbose)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        loss_val, acc_val = model.evaluate(X_val, y_val,\n",
    "                                           verbose=0, batch_size=batch_size)\n",
    "        \n",
    "        loss_train, acc_train = model.evaluate(X_test, y_test,\n",
    "                                               verbose=0, batch_size=batch_size)\n",
    "        \n",
    "        print('Val/Train Loss:', str(loss_val) + '/' +str(loss_train),\n",
    "              'Val/Train Acc:', str(acc_val) + '/' + str(acc_train))\n",
    "    \n",
    "    return model, partial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all 3 models\n",
    "def train_models(dataset, lr, batch_size, max_epoch, verbose=2, return_model=False):\n",
    "    y_train, X_b, X_images = dataset\n",
    "    y_train_full, y_val, \\\n",
    "    X_b_full, X_b_val, \\\n",
    "    X_images_full, X_images_val = train_test_split(y_train, X_b, X_images, random_state=687, train_size=0.9)\n",
    "\n",
    "    y_train, y_test, \\\n",
    "    X_b_train, X_b_test, \\\n",
    "    X_images_train, X_images_test = train_test_split(y_train, X_b, X_images, random_state=576, train_size=0.85)\n",
    "\n",
    "    if train_b:\n",
    "        if verbose > 0:\n",
    "            print(\"Training bandwidth network\")\n",
    "        data_b1 = (X_b_train, y_train, X_b_test, y_test, X_b_val, y_val)\n",
    "        model_b, model_b_cut = gen_model_weights(lr, 1e-6, 3, 'relu', batch_size, max_epoch, 'model_b',\n",
    "                                                 data=data_b1, verbose=verbose)\n",
    "        \n",
    "    if train_img:\n",
    "        if verbose > 0:\n",
    "            print(\"Training image network\")\n",
    "        data_images = (X_images_train, y_train, X_images_test, y_test, X_images_val, y_val)\n",
    "        model_images, model_images_cut = gen_model_weights(lr, 1e-6, 3, 'relu', batch_size, max_epoch, 'model_img',\n",
    "                                                           data_images, verbose=verbose)\n",
    "        \n",
    "    if train_total:\n",
    "        common_model = combined_model(model_b_cut, model_images_cut, lr/2, 1e-7)\n",
    "        common_x_train = [X_b_full, X_images_full]\n",
    "        common_y_train = y_train_full\n",
    "        common_x_val = [X_b_val, X_images_val]\n",
    "        common_y_val = y_val\n",
    "        if verbose > 0:\n",
    "            print(\"Training common network\")\n",
    "        # callbacks = [ModelCheckpoint(\"common\", save_best_only=True, monitor=\"val_loss\")]\n",
    "        callbacks = [ModelCheckpoint(\"common.keras\", save_best_only=True, monitor=\"val_loss\")]  # 확장자 .keras 추가\n",
    "        try:\n",
    "            # fit_generator -> fit\n",
    "            common_model.fit(gen_flow_multi_inputs(X_b_full, X_images_full, y_train_full, batch_size),\n",
    "                                       epochs=30,\n",
    "                                    #    steps_per_epoch=len(X_b_full) / batch_size,    # 실수로 타입 오류 발생\n",
    "                                       steps_per_epoch=round(len(X_b_full) / batch_size),\n",
    "                                       validation_data=(common_x_val, common_y_val), verbose=1,\n",
    "                                       callbacks=callbacks)\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        # common_model.load_weights(filepath=\"common\")\n",
    "        common_model.load_weights(filepath=\"common.keras\")  # 확장자 .keras 추가\n",
    "        loss_val, acc_val = common_model.evaluate(common_x_val, common_y_val,\n",
    "                                                  verbose=0, batch_size=batch_size)\n",
    "        loss_train, acc_train = common_model.evaluate(common_x_train, common_y_train,\n",
    "                                                      verbose=0, batch_size=batch_size)\n",
    "        if verbose > 0:\n",
    "            print(\"Loss:\", loss_val, \"Acc:\", acc_val)\n",
    "    if return_model:\n",
    "        return common_model\n",
    "    else:\n",
    "        return (loss_train, acc_train), (loss_val, acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters that are used in training assumes that you have enough computational power to process all the data.\n",
    "\n",
    "(Don't know if it is obvious or not) The important moment here is to save 3 sets, since if you are selecting model based on a validation set it affects final performance since it causes inderect observations of validation set and affect final evaluation score.\n",
    "\n",
    "**DeepL 번역**  \n",
    "\n",
    "학습에 사용되는 모델 매개변수는 모든 데이터를 처리할 수 있는 충분한 계산 능력이 있다고 가정합니다.\n",
    "\n",
    "(당연한 말인지 아닌지 모르겠습니다.) 여기서 중요한 순간은 검증 세트를 기반으로 모델을 선택하는 경우 검증 세트의 간접 관찰이 발생하여 최종 평가 점수에 영향을 미치기 때문에 3세트를 저장하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters i got are\n",
    "# epochs: 250\n",
    "# leraning rate: 8e-5\n",
    "# batch size: 32\n",
    "# common_model = train_models((y_train, X_b, X_images), 7e-04, 32, 50, 1, return_model=True)\n",
    "# 커널 충돌로 다음 셀이 실행 안 됨. 이 셀은 전부 실행되고 충돌 발생(numpy 충돌로 추측). 해결 못 함\n",
    "# 참고: https://github.com/microsoft/vscode-jupyter/wiki/Kernel-crashes\n",
    "common_model = train_models((y_train, X_b, X_images), 7e-04, 32, 1, 1, return_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The filtration step for RGB images may take a lot of time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_submission:\n",
    "    print(\"Reading test dataset\")\n",
    "    test = pd.read_json(\"./input/005_statoil-iceberg-classifier-challenge/test.json\")\n",
    "    y_fin, X_fin_b, X_fin_img = create_dataset(test, False)\n",
    "    print(\"predicting\")\n",
    "    prediction = common_model.predict([X_fin_b, X_fin_img], verbose=1, batch_size=32)\n",
    "    print(\"Submitting\")\n",
    "    submission = pd.DataFrame({\"id\": test[\"id\"], \"is_iceberg\": prediction.reshape((prediction.shape[0]))})\n",
    "\n",
    "    submission.to_csv(\"./submission.csv\", index=False)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "\n",
    "- Add features from https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python\n",
    "- Modify base model and train different models for pictures and bandwidth\n",
    "- Select denoising algorithm more meaningfully\n",
    "- Use XBG on output features of convolutional nets\n",
    "- Train denoising autoencoder on train and test data ot extract additional features and clean data\n",
    "- Data preprocessing parallelization\n",
    "\n",
    "**DeepL 번역**  \n",
    "\n",
    "**TODO**:\n",
    "- https://www.kaggle.com/muonneutrino/exploration-transforming-images-in-python 에서 기능 추가하기\n",
    "- 기본 모델을 수정하고 사진 및 대역폭에 대해 다른 모델을 훈련합니다.\n",
    "- 노이즈 제거 알고리즘을 더 의미있게 선택\n",
    "- 컨볼루션 네트워크의 출력 특징에 XBG 사용\n",
    "- 훈련 및 테스트 데이터에서 노이즈 제거 자동 인코더를 훈련하고 추가 기능을 추출하고 데이터를 정리합니다.\n",
    "- 데이터 전처리 병렬화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
